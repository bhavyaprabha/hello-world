{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r'C:\\Users\\bhavrang\\Documents\\Analytics vidhya\\GlobalDataChallenge-II\\global_data_science_challenge_2_public-master/data/gdsc2_public.csv'\n",
    "df=pd.read_csv(file_path, sep=';', parse_dates=['timestamp'])\n",
    "df=df.sort_values(by=['work_item','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['from_phase'].fillna('Start',inplace=True)\n",
    "df['to_phase'].fillna('End',inplace=True)\n",
    "df.components.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_item</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_in_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WI_000001</td>\n",
       "      <td>2015-01-02 14:39:14</td>\n",
       "      <td>2015-01-27 11:36:51</td>\n",
       "      <td>24 days 20:57:37</td>\n",
       "      <td>24.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WI_000002</td>\n",
       "      <td>2015-01-02 15:04:20</td>\n",
       "      <td>2015-01-14 09:46:37</td>\n",
       "      <td>11 days 18:42:17</td>\n",
       "      <td>11.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WI_000003</td>\n",
       "      <td>2015-01-02 15:28:22</td>\n",
       "      <td>2015-02-26 11:50:37</td>\n",
       "      <td>54 days 20:22:15</td>\n",
       "      <td>54.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WI_000004</td>\n",
       "      <td>2015-01-02 15:33:54</td>\n",
       "      <td>2015-01-28 09:11:05</td>\n",
       "      <td>25 days 17:37:11</td>\n",
       "      <td>25.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WI_000005</td>\n",
       "      <td>2015-01-02 16:32:11</td>\n",
       "      <td>2015-02-04 12:57:49</td>\n",
       "      <td>32 days 20:25:38</td>\n",
       "      <td>32.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_item               start                 end         duration  \\\n",
       "0  WI_000001 2015-01-02 14:39:14 2015-01-27 11:36:51 24 days 20:57:37   \n",
       "1  WI_000002 2015-01-02 15:04:20 2015-01-14 09:46:37 11 days 18:42:17   \n",
       "2  WI_000003 2015-01-02 15:28:22 2015-02-26 11:50:37 54 days 20:22:15   \n",
       "3  WI_000004 2015-01-02 15:33:54 2015-01-28 09:11:05 25 days 17:37:11   \n",
       "4  WI_000005 2015-01-02 16:32:11 2015-02-04 12:57:49 32 days 20:25:38   \n",
       "\n",
       "   duration_in_days  \n",
       "0             24.87  \n",
       "1             11.78  \n",
       "2             54.85  \n",
       "3             25.73  \n",
       "4             32.85  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_times=df[df['from_phase']=='Start'][['work_item','timestamp']]\n",
    "end_times=df[df['to_phase']=='End'][['work_item','timestamp']]\n",
    "times=pd.merge(start_times,end_times,on='work_item',how='left')\n",
    "times['duration']=times['timestamp_y']-times['timestamp_x']\n",
    "times['duration_in_days'] = times['duration'].apply(lambda x: round(x.total_seconds() / (24*3600), 2))\n",
    "times.rename(columns={'timestamp_x': 'start', 'timestamp_y': 'end'}, inplace=True)\n",
    "times.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_per_day=times.resample('D',on='start')['work_item'].count().rename('open_tickets_per_day')\n",
    "is_closed = times['end'].notnull()\n",
    "closed_per_day = times.loc[is_closed].resample('D', on='end')['work_item'].count().rename('closed_tickets_per_day')\n",
    "tickets_df = (pd.concat([open_per_day, closed_per_day], axis=1) # Join the two dataframes\n",
    "                .fillna(0)                                      # Replace NaNs by 0 for those days when no tickets are opened or closed\n",
    "                .astype(int)                                    # While we're at it, all counts are integers\n",
    "                .reset_index()                                  # timestamp_x is used as index, move it back to a column\n",
    "                .rename(columns={'start': 'date'})        # and rename it to ‘date’\n",
    "             )\n",
    "tickets_df['open_tickets_total'] = tickets_df['open_tickets_per_day'].cumsum()\n",
    "tickets_df['closed_tickets_total'] = tickets_df['closed_tickets_per_day'].cumsum()\n",
    "tickets_df['wip_tickets_total'] = tickets_df['open_tickets_total'] - tickets_df['closed_tickets_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_times = times[times['duration'].notnull()]\n",
    "open_times = times[times['duration'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_date_str = '01.01.2018'\n",
    "sep_date = dt.datetime.strptime(sep_date_str, '%d.%m.%Y')\n",
    "train_times = closed_times[closed_times.end <= sep_date]\n",
    "test_times = closed_times[(closed_times.end > sep_date) & (closed_times.start <= sep_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_work_items = set(train_times.work_item)  \n",
    "test_work_items = set(test_times.work_item)  \n",
    "df_start_only = df[df.from_phase == 'Start']\n",
    "train_df = df_start_only[df_start_only['work_item'].isin(train_work_items)]  \n",
    "test_df = df_start_only[df_start_only['work_item'].isin(test_work_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(actuals: pd.DataFrame, predictions: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Computes the root mean square log error between the actuals and predictions.\n",
    "    Raises and error if there are multiple predictions for a single work item, or if there are missing predictions\n",
    "    :param actuals: A DataFrame with the columns 'work_item' and 'duration_in_days'\n",
    "    :param predictions: A DataFrame with the columns 'work_item' and 'predictions'\n",
    "    :return: RMSLE between actuals and predictions\n",
    "    \"\"\"\n",
    "    assert len(actuals) == len(predictions)\n",
    "    assert set(actuals.work_item.values) == set(predictions.work_item.values)\n",
    "    actuals_values = actuals.duration_in_days.values\n",
    "    predictions_values = predictions.predictions.values\n",
    "    rmsle = np.sqrt(sum(((np.log(actuals_values + 1) - np.log(predictions_values + 1)) ** 2)) / len(actuals_values))\n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###KNeighbours regression######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.670509639375778\n",
      "1.4284558887117986\n"
     ]
    }
   ],
   "source": [
    "## onehot encoding the features\n",
    "cols_to_encode=['work_type','work_priority','domain','platform','components']\n",
    "onehotencoder = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "train_features = onehotencoder.fit_transform(train_df[cols_to_encode])\n",
    "test_features = onehotencoder.transform(test_df[cols_to_encode])\n",
    "##applying knn algorithm\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(train_features, train_times.duration_in_days)\n",
    "#calculating rmsle value\n",
    "train_predictions = pd.DataFrame(train_times.work_item)  \n",
    "train_predictions['predictions'] = knn.predict(train_features)\n",
    "test_predictions = pd.DataFrame(test_times.work_item)\n",
    "test_predictions['predictions'] = knn.predict(test_features)\n",
    "print(rmsle(train_times, train_predictions))\n",
    "print(rmsle(test_times, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All work items that are finished become our training data, all open work items our test data\n",
    "closed_work_items = set(closed_times.work_item)  \n",
    "open_work_items = set(open_times.work_item)  \n",
    "closed_df = df_start_only[df_start_only.work_item.isin(closed_work_items)]  \n",
    "open_df = df_start_only[df_start_only.work_item.isin(open_work_items)]\n",
    "\n",
    "# Compute the features\n",
    "onehotencoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "cols_to_encode = ['work_type', 'work_priority','domain', 'platform','components']\n",
    "closed_features = onehotencoder.fit_transform(closed_df[cols_to_encode])\n",
    "open_features = onehotencoder.transform(open_df[cols_to_encode])\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(closed_features, closed_times.duration_in_days)\n",
    "open_predictions = pd.DataFrame(open_times.work_item)\n",
    "open_predictions['predictions'] = model.predict(open_features)\n",
    "\n",
    "with open('open_predictions_knn_wt_wp1.csv', 'w') as f:\n",
    "    open_predictions.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######linear regression#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(closed_features,closed_times.duration_in_days)\n",
    "predictions = lm.predict(open_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_predictions = pd.DataFrame(open_times.work_item)\n",
    "open_predictions['predictions'] = lm.predict(open_features)\n",
    "with open('open_predictions_lr_wt_wp1.csv', 'w') as f:\n",
    "    open_predictions.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, train_features, train_times, test_features, test_times):\n",
    "    model.fit(train_features, train_times.duration_in_days)\n",
    "    train_predictions = pd.DataFrame(train_times.work_item)  \n",
    "    train_predictions['predictions'] = model.predict(train_features)\n",
    "    test_predictions = pd.DataFrame(test_times.work_item)\n",
    "    test_predictions['predictions'] = model.predict(test_features)\n",
    "    train_rmsle = rmsle(train_times, train_predictions)\n",
    "    test_rmsle = rmsle(test_times, test_predictions)\n",
    "    return train_rmsle, test_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orig_model(model, closed_features, closed_times, open_features, open_times):\n",
    "    model.fit(closed_features, closed_times.duration_in_days)\n",
    "    closed_predictions = pd.DataFrame(closed_times.work_item)  \n",
    "    closed_predictions['predictions'] = model.predict(closed_features)\n",
    "    open_predictions = pd.DataFrame(open_times.work_item)\n",
    "    open_predictions['predictions'] = model.predict(open_features)\n",
    "    closed_rmsle = rmsle(closed_times, closed_predictions)\n",
    "    open_rmsle = rmsle(open_times, open_predictions)\n",
    "    with open('open_predictions_dtr.csv', 'w') as f:\n",
    "        open_predictions.to_csv(f, index=False)\n",
    "    return closed_rmsle, open_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhavrang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\bhavrang\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.764577435636904, 1.250806711915415)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "eval_model(model, train_features, train_times, test_features, test_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=1)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8160385734183933, nan)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model(model, closed_features, closed_times, open_features, open_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8105012372931064, 1.2973108103859685)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth=5)\n",
    "eval_model(model, train_features, train_times, test_features, test_times)\n",
    "#orig_model(model, closed_features, closed_times, open_features, open_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pr_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f790e63fa980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpr_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpr_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'work_item'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosed_work_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnewtestdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpr_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpr_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'work_item'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_work_items\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pr_df' is not defined"
     ]
    }
   ],
   "source": [
    "newdf=pr_df[pr_df['work_item'].isin(closed_work_items)]\n",
    "newtestdf=pr_df[pr_df['work_item'].isin(open_work_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_df=pd.get_dummies(df,columns=['work_type','work_priority','domain','platform','components','to_phase','to_resource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(closed_work_items) #10522\n",
    "len(open_work_items) #1042"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fph=pd.DataFrame(newdf.groupby('work_item')['from_phase'].unique().rename('from_phases'))\n",
    "tph=pd.DataFrame(newdf.groupby('work_item')['to_phase'].unique().rename('to_phases'))\n",
    "frs=pd.DataFrame(newdf.groupby('work_item')['from_resource'].unique().rename(name='from_resources'))\n",
    "trs=pd.DataFrame(newdf.groupby('work_item')['to_resource'].unique().rename(name='to_resources'))\n",
    "tfph=pd.DataFrame(newtestdf.groupby('work_item')['from_phase'].unique().rename('from_phases'))\n",
    "ttph=pd.DataFrame(newtestdf.groupby('work_item')['to_phase'].unique().rename('to_phases'))\n",
    "tfrs=pd.DataFrame(newtestdf.groupby('work_item')['from_resource'].unique().rename(name='from_resources'))\n",
    "ttrs=pd.DataFrame(newtestdf.groupby('work_item')['to_resource'].unique().rename(name='to_resources'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ph=pd.merge(fph,tph,on='work_item',how='left')\n",
    "rs=pd.merge(frs,trs,on='work_item',how='left')\n",
    "df1=pd.merge(ph,rs,on='work_item',how='left')\n",
    "tph=pd.merge(tfph,ttph,on='work_item',how='left')\n",
    "trs=pd.merge(tfrs,ttrs,on='work_item',how='left')\n",
    "tdf1=pd.merge(tph,trs,on='work_item',how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df1.rename(columns={'0_x':'from_resources','0_y':'to_resources'},inplace=True)\n",
    "tdf1.rename(columns={'0_x':'from_resources','0_y':'to_resources'},inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resdf=pd.merge(df1,newdf[newdf['from_phase']=='Start'],on='work_item',how='left')\n",
    "tresdf=pd.merge(tdf1,newtestdf[newtestdf['from_phase']=='Start'],on='work_item',how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "resdf.drop(['from_phase','to_phase','from_resource','to_resource'],inplace=True,axis=1)\n",
    "tresdf.drop(['from_phase','to_phase','from_resource','to_resource'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf=newdf.drop(['timestamp','from_phase','from_resource'],axis=1)\n",
    "tresdf=newtestdf.drop(['timestamp','from_phase','from_resource'],axis=1)\n",
    "resdf=resdf.groupby('work_item').sum()\n",
    "tresdf=tresdf.groupby('work_item').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf=pd.merge(resdf,closed_times,on='work_item',how='left')\n",
    "resdf.drop(['start','end','duration'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresdf=pd.merge(tresdf,open_times,on='work_item',how='left')\n",
    "tresdf.drop(['start','end','duration'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "traindummy=pd.get_dummies(newdf,columns=['to_phase','to_resource'])\n",
    "testdummy=pd.get_dummies(newtestdf,columns=['to_phase','to_resource'])\n",
    "traindummy=traindummy.groupby('work_item').sum()\n",
    "testdummy=testdummy.groupby('work_item').sum()\n",
    "resdf=pd.merge(resdf,traindummy,on='work_item',how='left')\n",
    "tresdf=pd.merge(tresdf,testdummy,on='work_item',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=resdf.drop('duration_in_days',axis=1)\n",
    "y_train=resdf['duration_in_days']\n",
    "x_test=tresdf.drop('duration_in_days',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(x_train.drop(['work_item'],axis=1), y_train)\n",
    "#calculating rmsle value\n",
    "#y_test = pd.DataFrame(tresdf.work_item)  \n",
    "#y_test['predictions'] = knn.predict(x_test.drop(['work_item'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(tresdf.work_item)  \n",
    "y_test['predictions'] = knn.predict(x_test.drop(['work_item'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(x_train.drop(['work_item'],axis=1), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(x_train.drop(['work_item'],axis=1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(tresdf.work_item)  \n",
    "y_test['predictions'] =lm.predict(x_test.drop(['work_item'],axis=1))\n",
    "y_test.to_csv('new_xgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import source_func "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'source_func' from 'C:\\\\Users\\\\bhavrang\\\\Documents\\\\Analytics vidhya\\\\GlobalDataChallenge-II\\\\source_func.py'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(source_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'func']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(source_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside function\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(source_func.func())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
